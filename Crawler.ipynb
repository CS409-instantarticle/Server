{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Article Crawler by Section\n",
    "import requests \n",
    "import json\n",
    "import sqlite3\n",
    "import pickle \n",
    "import urllib\n",
    "import time\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from timeit import default_timer as timer\n",
    "from multiprocessing import Process\n",
    "import random\n",
    "\n",
    "# Constants - Section ID\n",
    "sectionId_Politics = 100\n",
    "sectionId_Economy = 101\n",
    "sectionId_Society = 102\n",
    "sectionId_IT = 105\n",
    "sectionId_Life = 103\n",
    "sectionId_World = 104\n",
    "\n",
    "section = {\n",
    "    '정치' : sectionId_Politics,\n",
    "    '경제' : sectionId_Economy,\n",
    "    '사회' : sectionId_Society,\n",
    "    'IT'   : sectionId_IT,\n",
    "    '생활' : sectionId_Life,\n",
    "    '세계' : sectionId_World\n",
    "}\n",
    "\n",
    "dbName = {\n",
    "    '정치' : \"article_politics\",\n",
    "    '경제' : \"article_economy\",\n",
    "    '사회' : \"article_society\",\n",
    "    'IT'   : \"article_it\",\n",
    "    '생활' : \"article_life\",\n",
    "    '세계' : \"article_world\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터베이스 초기화\n",
    "\n",
    "conn_all = sqlite3.connect(\"article_all.db\", isolation_level=None)\n",
    "conn_politics = sqlite3.connect(\"article_politics.db\", isolation_level=None)\n",
    "conn_economy = sqlite3.connect(\"article_economy.db\", isolation_level=None)\n",
    "conn_society = sqlite3.connect(\"article_society.db\", isolation_level=None)\n",
    "conn_it = sqlite3.connect(\"article_it.db\", isolation_level=None)\n",
    "conn_life = sqlite3.connect(\"article_life.db\", isolation_level=None)\n",
    "conn_world = sqlite3.connect(\"article_world.db\", isolation_level=None)\n",
    "\n",
    "c_all = conn_all.cursor()\n",
    "c_politics = conn_politics.cursor()\n",
    "c_economy = conn_economy.cursor()\n",
    "c_society = conn_society.cursor()\n",
    "c_it = conn_it.cursor()\n",
    "c_life = conn_life.cursor()\n",
    "c_world = conn_world.cursor()\n",
    "\n",
    "c_all.execute('drop table if exists article_all;')\n",
    "c_politics.execute('drop table if exists article_politics;')\n",
    "c_economy.execute('drop table if exists article_economy;')\n",
    "c_society.execute('drop table if exists article_society;')\n",
    "c_it.execute('drop table if exists article_it;')\n",
    "c_life.execute('drop table if exists article_life;')\n",
    "c_world.execute('drop table if exists article_world;')\n",
    "\n",
    "table_scheme = '''(\n",
    "        idx INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        itemid text NOT NULL UNIQUE,\n",
    "        json text\n",
    ")\n",
    "'''\n",
    "\n",
    "c_all.execute('''create table if not exists article_all %s;''' % table_scheme);\n",
    "c_politics.execute('''create table if not exists article_politics %s;''' % table_scheme);\n",
    "c_economy.execute('''create table if not exists article_economy %s;''' % table_scheme);\n",
    "c_society.execute('''create table if not exists article_society %s;''' % table_scheme);\n",
    "c_it.execute('''create table if not exists article_it %s;''' % table_scheme);\n",
    "c_life.execute('''create table if not exists article_life %s;''' % table_scheme);\n",
    "c_world.execute('''create table if not exists article_world %s;''' % table_scheme);\n",
    "\n",
    "conn = {\n",
    "    \"article_all\" : conn_all,\n",
    "    \"article_politics\" : conn_politics,\n",
    "    \"article_economy\" : conn_economy,\n",
    "    \"article_society\" : conn_society,\n",
    "    \"article_it\" : conn_it,\n",
    "    \"article_life\" : conn_life,\n",
    "    \"article_world\" : conn_world\n",
    "}\n",
    "\n",
    "\n",
    "c = {\n",
    "    \"article_all\" : c_all,\n",
    "    \"article_politics\" : c_politics,\n",
    "    \"article_economy\" : c_economy,\n",
    "    \"article_society\" : c_society,\n",
    "    \"article_it\" : c_it,\n",
    "    \"article_life\" : c_life,\n",
    "    \"article_world\" : c_world\n",
    "}\n",
    "\n",
    "for x in conn.values():\n",
    "    x.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#test\\ninsert_article(\"article_all\", \\'1233\\', \"{\\'asdf\\' : \\'asdf\"asdfasdf\"\\'}\")\\ninsert_article(\"article_all\", \\'1234\\', \"{\\'asdf\\' : \\'asdf\"asdfasdf\"\\'}\")\\ninsert_article(\"article_all\", \\'1235\\', \"{\\'asdf\\' : \\'asdf\"asdfasdf\"\\'}\")\\ninsert_article(\"article_all\", \\'1236\\', \"{\\'asdf\\' : \\'asdf\"asdfasdf\"\\'}\")\\ninsert_article(\"article_all\", \\'1237\\', \"{\\'asdf\\' : \\'asdf\"asdfasdf\"\\'}\")\\nprint(select_article(\\'article_all\\', 3))\\nc.execute(\"DELETE FROM article_all where 1 > 0;\")\\nconn.commit()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# db 조작 명령어\n",
    "\n",
    "def insert_article(tablename, itemid, json):\n",
    "    # dict 안의 특수기호로 인해 바로 저장 불가능\n",
    "    pdata = pickle.dumps(json, pickle.HIGHEST_PROTOCOL)\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        \n",
    "        try:\n",
    "            con = conn[tablename]\n",
    "            con.execute('insert into %s (itemid, json) values (?, :data)' % tablename, (itemid, sqlite3.Binary(pdata)))\n",
    "            #con.commit()\n",
    "            break\n",
    "            \n",
    "        except sqlite3.OperationalError:\n",
    "            if cnt > 5: break\n",
    "            print(\"rest %s\" % itemid)\n",
    "            time.sleep(0.002 * random.randint(1, 5))\n",
    "            cnt += 1\n",
    "            \n",
    "        except sqlite3.IntegrityError:\n",
    "            print(\"skip %s\" % itemid)\n",
    "            break\n",
    "    return\n",
    "\n",
    "\n",
    "def select_article(tablename, limit):\n",
    "    cur = c[tablename]\n",
    "    cur.execute(\"select idx, itemid, json from %s order by idx desc limit %s \" % (tablename, limit))\n",
    "    return [(row[0], row[1], pickle.loads(row[2])) for row in cur]\n",
    "\n",
    "'''\n",
    "#test\n",
    "insert_article(\"article_all\", '1233', \"{'asdf' : 'asdf\\\"asdfasdf\\\"'}\")\n",
    "insert_article(\"article_all\", '1234', \"{'asdf' : 'asdf\\\"asdfasdf\\\"'}\")\n",
    "insert_article(\"article_all\", '1235', \"{'asdf' : 'asdf\\\"asdfasdf\\\"'}\")\n",
    "insert_article(\"article_all\", '1236', \"{'asdf' : 'asdf\\\"asdfasdf\\\"'}\")\n",
    "insert_article(\"article_all\", '1237', \"{'asdf' : 'asdf\\\"asdfasdf\\\"'}\")\n",
    "print(select_article('article_all', 3))\n",
    "c.execute(\"DELETE FROM article_all where 1 > 0;\")\n",
    "conn.commit()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ns = timer()\\nfor i in range(101, 300):\\n    insert_article(\"article_all\", str(i), \"{\\'asdf\\' : \\'asdf\"asdfasdf\"\\'}\")\\ne = timer()\\n\\nprint(e - s)\\n\\ns = timer()\\nprint(select_article(\"article_all\", 40))\\ne = timer()\\nprint(e - s)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "s = timer()\n",
    "for i in range(101, 300):\n",
    "    insert_article(\"article_all\", str(i), \"{'asdf' : 'asdf\\\"asdfasdf\\\"'}\")\n",
    "e = timer()\n",
    "\n",
    "print(e - s)\n",
    "\n",
    "s = timer()\n",
    "print(select_article(\"article_all\", 40))\n",
    "e = timer()\n",
    "print(e - s)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NewsArticle:\n",
    "    ArticleID = 0\n",
    "    itemId = None\n",
    "    ArticleTitle = None\n",
    "    SectionName = None\n",
    "    ArticleDate = None\n",
    "    ThumbnailImageURL = None\n",
    "    Video = False\n",
    "    Link = None\n",
    "    Press = None\n",
    "    Raw_contents = None\n",
    "    Contents = []\n",
    "\n",
    "    # 이니셜라이저 : 각 기사별 json 받아서 데이터 타입에 맞게 저장\n",
    "    def __init__(self, json):\n",
    "        self.itemId = json[\"itemId\"]\n",
    "        self.ArticleID = json[\"articleId\"]\n",
    "        self.ArticleTitle = json[\"title\"]\n",
    "        self.ArticleDate = json[\"standardFullDate\"] if 'standardFullDate' in json.keys() else None\n",
    "        self.ThumbnailImageURL = str(json[\"imageUrl\"])\n",
    "        self.Video = json[\"videoType\"]\n",
    "        self.Press = json[\"officeName\"]\n",
    "        self.Link = \"http://m.news.naver.com\" + json[\"linkUrl\"]\n",
    "        self.SectionName = (\n",
    "            json[\"sectionName\"] if json[\"sectionName\"] else None)\n",
    "        self.get_contents()\n",
    "        return\n",
    "    \n",
    "    \n",
    "    # json 스트링 리턴\n",
    "    def __str__(self):\n",
    "        d = dict()\n",
    "        d[\"ArticleID\"] = str(self.ArticleID)\n",
    "        d[\"ArticleTitle\"] = str(self.ArticleTitle)\n",
    "        d[\"SectionName\"] = str(self.SectionName)\n",
    "        d[\"ArticleDate\"] = str(self.ArticleDate)\n",
    "        d[\"Press\"] = str(self.Press)\n",
    "        d[\"ThumbnailImageURL\"] = str(self.ThumbnailImageURL)\n",
    "        d[\"Video\"] = str(self.Video)\n",
    "        d[\"Link\"] = str(self.Link)\n",
    "        d[\"Contents\"] = (self.Contents)\n",
    "        return str(d)\n",
    "    \n",
    "    \n",
    "    # 컨텐츠 내용 파싱\n",
    "    def get_contents(self):\n",
    "        #print(self.ArticleTitle)\n",
    "        texts = get_text(self.Link)\n",
    "        self.Raw_contents = texts\n",
    "        self.Contents = jsonify_content(texts)\n",
    "        return\n",
    "      \n",
    "    '''\n",
    "    \n",
    "    # 파일 이름 저장 : 날짜 및 아티클 ID 기준\n",
    "    def getFileName(self):\n",
    "        fileName = \"%s%s\" % \\\n",
    "            (self.ArticleDate \\\n",
    "             .replace(\":\", \"\") \\\n",
    "             .replace(\"-\", \"\") \\\n",
    "             .replace(\" \", \"\"), \n",
    "             self.ArticleID)\n",
    "        return fileName\n",
    "        \n",
    "        \n",
    "    # 파일로 기록\n",
    "    def write(self):\n",
    "        fileName = self.getFileName()\n",
    "        directory = \"articles/%s\" % fileName\n",
    "\n",
    "        try:\n",
    "            f = open(directory, \"r\")\n",
    "        except IOError:\n",
    "            if self.SectionName:\n",
    "                print(self.SectionName)\n",
    "                with open(\"articles/\" + self.SectionName + fileName, \"w\") as f:\n",
    "                    f.write(str(self))\n",
    "            with open(directory, \"w\") as f:\n",
    "                f.write(str(self))\n",
    "            return\n",
    "        # if reached : file exists\n",
    "        raise IOError    \n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_text : URL(str) ->> BS element\n",
    "def get_text(URL):\n",
    "    source_code_from_URL = str(urllib.request.urlopen(URL).read(), \"utf-8\").replace(\"<br>\", \"<br/>\").replace(\"<br/><br/>\", \"<br/>\")\n",
    "    soup = BS(source_code_from_URL, 'html.parser')\n",
    "    result = soup.find_all('div', id=\"dic_area\")\n",
    "\n",
    "    # entertain 뉴스를 레퍼런스로 하는 경우 별도의 핸들링 필요\n",
    "    if not result:\n",
    "        #print(URL)\n",
    "        source_code_from_URL = str(urllib.request.urlopen(\n",
    "            URL.replace(\"m.news.naver.com\", \"m.entertain.naver.com\")).read(), \"utf-8\").replace(\"<br>\", \"<br/>\").replace(\"<br/><br/>\", \"<br/>\")\n",
    "        soup = BS(source_code_from_URL, 'html.parser')\n",
    "        result = soup.find_all('div', id=\"contentArea\")\n",
    "    \n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BS contents ->>  [indexed dictionary, ...]\n",
    "def jsonify_content(content):\n",
    "\n",
    "    # BS.contents는 html 태그 안의 모든 first child를 리스트로 반환\n",
    "    # 태그가 없어도 무방하므로 본문 내용까지 별도의 child로 리턴됨\n",
    "    # 기사 앞뒤의 빈 칸(탭, 줄바꿈 기호 등)을 잘라내고 br 태그를 제거함\n",
    "    content_list = content.contents\n",
    "    x = list(filter(lambda s : s != \"<br/>\", map(lambda s: str(s).strip(), content_list)))\n",
    "\n",
    "    # 각 object에 기사 요소의 배치 순서를 지시\n",
    "    index = 0\n",
    "\n",
    "    # json_list에 각 기사 요소를 순서대로 담아 리턴\n",
    "\n",
    "    json_list = []\n",
    "    # 텍스트 타입에 따라 분류\n",
    "    # type : text, video, image, link\n",
    "    for i in x:\n",
    "\n",
    "        # 잘못 나온 놈은 걸러야 한다. 인덱스 추가 안하고 다음 요소 탐색\n",
    "        if i == \"\":\n",
    "            continue\n",
    "\n",
    "        # 여기부턴 어쨌든 요소에 속함.\n",
    "        # HTML 태그가 하나도 없으면 텍스트로 분류\n",
    "        if not \"<\" in i:\n",
    "            json_list.append({'ArticleIndex': index, \"ArticleType\": \"text\", 'content' : i})\n",
    "\n",
    "        # 태그가 있는 요소들은 다음과 같이 분류함:\n",
    "        else:\n",
    "            bs = BS(i, 'html.parser')\n",
    "\n",
    "            # 비디오 태그 : To Be Implemented\n",
    "            if \"<iframe\" in i:\n",
    "                video_url = bs.find('iframe').get('src')\n",
    "                json_list.append({'ArticleIndex': index, \"ArticleType\": \"text\", 'content': video_url})\n",
    "\n",
    "            elif \"video_area\" in i:\n",
    "                #print(i)\n",
    "                json_list.append({'ArticleIndex': index, \"ArticleType\": \"text\", \n",
    "                                  'content': \"http://news.video.p.rmcnmv.naver.com/owfs_rmc/read/NEWS_2017_05_26_3/531C05F3C304F34C0F330E6E936E1FC3388_muploader_b_480P_854_1024_128.mp4?_lsu_sa_=632577fcc1be6046fdda357b66c57bba4ecf3f1831089f0633875ec1c74a3f2570240aed61357008709b3a129034fbc5effbc03b5726a5f16d6f884f367d5fa70774723c3e1698cc965eedfef0ec4a5a\"})\n",
    "                #video_url = bs.find('video').get('data-src')\n",
    "                #json_list.append({'ArticleIndex': index, \"ArticleType\": \"video\", 'content': video_url})\n",
    "\n",
    "            # 이미지 태그 : 대부분 span으로 묶여 있음. 사진과 태그 포함\n",
    "            # 다만 다른 형식에 span이 사용될 수 있으므로 img를 이용함\n",
    "            elif \"<img\" in i:\n",
    "                #print('image')\n",
    "                img_url = bs.find('img').get('data-src')\n",
    "                img_tag = bs.find('em', class_='img_desc')\n",
    "                # 이미지 태그가 없으면 빈 스트링을 저장함.\n",
    "                if img_tag: img_tag = img_tag.text\n",
    "                else: img_tag = \"\"\n",
    "                json_list.append({'ArticleIndex': index, \"ArticleType\": \"image\", 'content': img_url, 'tag' : img_tag})\n",
    "\n",
    "\n",
    "            # 링크 태그 : a 안에 들어 있음\n",
    "            # 네이버 기사는 본문 안에 링크 삽입 잘 안하므로 a 안의 요소만 따도 무방\n",
    "            elif \"<a\" in i:\n",
    "                link_url = bs.find('a').get('href')\n",
    "                link_text = bs.find('a').text\n",
    "                json_list.append({'ArticleIndex': index, \"ArticleType\": \"link\", 'url': link_url, 'content': link_text})\n",
    "\n",
    "            # 소제목 태그 : strong, em 등의 텍스트 요소를 포함함\n",
    "            elif any([\"<font\" in i, \"<strong\" in i, \"<b\" in i]):\n",
    "                json_list.append({'ArticleIndex': index, \"ArticleType\": \"strapline\", 'content': bs.text})\n",
    "\n",
    "            # 가끔 텍스트에 꺾쇠를 집어넣는 똥같은 언론사들이 있음\n",
    "            # 문과가 또...\n",
    "            # 이 경우는 텍스트로 분류\n",
    "            else:\n",
    "                json_list.append({'ArticleIndex': index, \"ArticleType\": \"text\", 'content': bs.text})\n",
    "\n",
    "        #print(index)\n",
    "        index += 1\n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# request first 12 extlements\n",
    "# sectionId : int --> [list-of Articles]\n",
    "def requestBySection(sectionName, limit=10, log=False):\n",
    "    \n",
    "    assert type(limit) == int\n",
    "    assert limit >= 1\n",
    "    \n",
    "    sectionId = section[sectionName]\n",
    "\n",
    "    if log:\n",
    "        print(\"section Name = %s\" % sectionName)\n",
    "        print(\"section ID = %s\" % sectionId)\n",
    "    \n",
    "    First_URL = 'http://m.news.naver.com/section/moreItemList.json?' + \"sectionId=%s\" % sectionId\n",
    "    response = requests.get(First_URL)\n",
    "    result = parse_response(response, log=log)\n",
    "    \n",
    "    articleList = result['articles']\n",
    "    \n",
    "    if log:\n",
    "        for article in result['articles']: \n",
    "            print(\"article ID : %s\" % article['itemId'])\n",
    "        \n",
    "    for i in range(1, limit):\n",
    "        data = dict()\n",
    "        data['sectionId'] = sectionId\n",
    "        data['componentId'] = result['componentId']\n",
    "        data['itemId'] = result['articles'][-1]['itemId']\n",
    "        \n",
    "        # 파일 이름 비교\n",
    "        \n",
    "        URL = \"http://m.news.naver.com/section/moreItemList.json\"\n",
    "        response = requests.post(URL, data=data)\n",
    "        result = parse_response(response, log=log)\n",
    "        \n",
    "        if log:\n",
    "            print(\"index : %s\" % i)\n",
    "            for article in result['articles']: \n",
    "                print(\"Item ID : %s\" % article['itemId'])\n",
    "\n",
    "        #for article in result['articles']:\n",
    "        #    print(article['itemId'])\n",
    "        articleList = articleList + result['articles']\n",
    "        \n",
    "    return articleList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# response --> {componentId: int, pageNavigation: int, articles: [article, ...]}\n",
    "def parse_response(response, log=False):\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()['message']\n",
    "        if result[\"success\"]:\n",
    "            #print(result['contents']['articles'][0].keys())\n",
    "            result = result['contents']\n",
    "\n",
    "            if log:\n",
    "                print()\n",
    "                print(\"-- Article log start --\")\n",
    "                print(result['componentId'])\n",
    "                print(result['pageNavigation'])\n",
    "                for article in result['articles']:\n",
    "                    for (k, v) in article.items():\n",
    "                        print (\"- %s : %s\" % (k, v))\n",
    "                    print()\n",
    "                print(\"-- Article log end --\")\n",
    "                print()\n",
    "                \n",
    "            return result\n",
    "\n",
    "        else:\n",
    "            print(\"Error with Naver request %s\" % result[\"success\"])\n",
    "            return False\n",
    "    else:\n",
    "        print(\"Error with HTTP code %s\" % response.status_code)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 메인화면 뉴스묶음 크롤링은 별도로 구현\n",
    "def request_list(k):\n",
    "    data = {\"page\": str(k)}\n",
    "    navernews_url = \"http://m.news.naver.com/mainNews/moreMainNews.json\"\n",
    "    r = requests.post(navernews_url, data=data)\n",
    "    data = json.loads(r.text)\n",
    "    #articleList = []\n",
    "    #for articleData in data['message']['itemList']:\n",
    "    #    # data의 데이터 선택 및 article 클래스 생성\n",
    "    #    article = NewsArticle(articleData)\n",
    "    #    articleList.append(article)\n",
    "    #return articleList\n",
    "    return data[\"message\"]['itemList']\n",
    "\n",
    "def requestMainSection(k):\n",
    "    l = list()\n",
    "    for i in range(k):\n",
    "        l = l + request_list(i)\n",
    "    return l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터베이스 삽입\n",
    "def section_newsCrawler(sectionName, limit):\n",
    "    sectionId = section[sectionName]\n",
    "    tableName = dbName[sectionName]\n",
    "    l = requestBySection(sectionName, limit=limit, log=False)\n",
    "    # 시간 역순\n",
    "    l.reverse()\n",
    "    for i in l:\n",
    "        j = NewsArticle(i)\n",
    "        insert_article(tableName, j.itemId, str(j))\n",
    "    return\n",
    "\n",
    "def main_newsCrawler(limit):\n",
    "    l = requestMainSection(limit)\n",
    "    l.reverse()\n",
    "    for i in l:\n",
    "        j = NewsArticle(i)\n",
    "        insert_article('article_all', j.itemId, str(j))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def crawl(limit):\n",
    "    processes = []\n",
    "    \n",
    "    p = Process(target=main_newsCrawler, args=(limit, ))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "\n",
    "    for sectionName in section.keys():\n",
    "        p = Process(target=section_newsCrawler, args=(sectionName, limit))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "crawl(40)\n",
    "end = timer()\n",
    "print(end - start)\n",
    "\n",
    "while True:\n",
    "    start = timer()\n",
    "    crawl(40)\n",
    "    end = timer()\n",
    "    print(end - start)\n",
    "    time.sleep(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
